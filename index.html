<!DOCTYPE html>  
<html lang="en-US">
   <head itemscope="" itemtype="https://schema.org/WebSite">
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}</style>
      <link rel="profile" href="http://gmpg.org/xfn/11">
      <title>ALQAC 2021 – Nguyen Lab</title>
      
   </head>
   <body class="page-template-default page page-id-256 group-blog no-banner" itemscope="" itemtype="https://schema.org/WebPage">
      <div id="page" class="site">
         <div class="page-header">
            <div class="container">
               <h1 class="page-title">ALQAC 2021</h1>
            </div>
         </div>
         <div id="acc-content">
            <!-- done for accessibility reasons -->        
            <div id="content" class="site-content">
               <div class="container">
                  <div class="row">
                     <div id="primary" class="content-area">
                        <main id="main" class="site-main" role="main">
                           <article id="post-256" class="post-256 page type-page status-publish hentry">
                              <div class="entry-content" itemprop="text">
                                 <p><strong>A</strong>utomated <strong>L</strong>egal <strong>Q</strong>uestion <strong>A</strong>nswering <strong>C</strong>ompetition (ALQAC)<br>Run in association with the International Conference on Knowledge and Systems Engineering</p>
                                 <p><strong>ALQAC-2021 CALL FOR TASK PARTICIPATION </strong><br>ALQAC-2021 Workshop: <strong>November 10-12, 2021</strong><br>ALQAC-2021 Registration due: <strong>July 15, 2021 </strong> </p>
                                 <p>Sponsored by<br><a href="https://www.jaist.ac.jp">Japan Advanced Institute of Science and Technology (JAIST)</a><br><a href="http://uet.vnu.edu.vn/">University of Engineering and Technology (VNU-UET)</a></p>
                                 <h2>Overview</h2>
                                 <p>As an associated event of KSE 2021, we are happy to announce the 1st <strong>Automated Legal Question Answering Competition (ALQAC 2021)</strong>. ALQAC includes 3 tasks for each language: (1) Legal Document Retrieval, (2) Legal Textual Entailment, and (3) Legal Question Answering. For the competition, we introduce the Legal Question Answering dataset – a manually annotated dataset based on well-known statute laws in <strong>Vietnamese </strong>and <strong>Thai</strong> Language. Through the competition, we aim to develop a research community on legal support systems.</p>
                                 <h2>Dataset</h2>
                                 <p>The dataset file formats are shown via examples as follows.</p>
                                 <ul>
                                    <li><strong>Legal Articles</strong>: Details about each article are in the following format:</li>
                                 </ul>
                                 <pre class="wp-block-code"><code>
        [
            {
            "id": "45/2019/QH14",
            "articles": [
                    {
                        "text": "The content of legal article",
                        "id": "1"
                    }
                ]
            }
        ]</code></pre>
                                 <ul>
                                    <li><strong>Annotation Samples</strong>: Details about each sample are in the following format:</li>
                                 </ul>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement",
                "label": true,
                "relevant_articles": [
                    {
                        "law_id": "45/2019/QH14",
                        "article_id": "1"
                    }
                ]
            }
        ]</code></pre>
                                 <h2>Tasks</h2>
                                 <h3>Tasks Description</h3>
                                 <h4>Task 1: Legal Document Retrieval</h4>
                                 <p>Task 1’s goal is to return articles that are related to a statement. An article is considered “relevant” to a statement <em>iff </em>the statement rightness can be entailed (as Yes/No) by the article. This task requires the retrieval of all the articles that are relevant to a query. </p>
                                 <p>Specifically, the input samples consists of:</p>
                                 <ul>
                                    <li><strong>Legal Articles</strong>: whose format is the same as <strong>Legal Articles</strong> described in the <strong>Dataset</strong> section.</li>
                                    <li><strong>Question</strong>: whose format is in JSON as follows:</li>
                                 </ul>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement"
            }
        ]</code></pre>
                                 <p>The system should retrieve all the relevant articles as follows:</p>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement",
                "label": true,
                "relevant_articles": [
                    {
                        "law_id": "45/2019/QH14",
                        "article_id": "1"
                    }
                ]
            }
        ]</code></pre>
                                 <p>Note that <em>“relevant_articles”</em> are the list of all relevant articles of the questions/statements.</p>
                                 <p>The evaluation methods are precision, recall and F2-measure as follows:</p>
                                 <p></p>
                                 <p></p>
                                 <p></p>
                                 <center>
                                    Precision<sub>i</sub> =&nbsp;&nbsp;&nbsp; <span style="text-decoration: underline;">the number of correctly retrieved articles of query i<sup>th</sup></span><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; the number of retrieved articles of query i<sup>th</sup> ,
                                    <p></p>
                                    <p></p>
                                    <p>Recall<sub>i</sub> =&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span style="text-decoration: underline;">the number of correctly retrieved cases(paragraphs) of query i<sup>th</sup></span><br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;the number of relevant cases(paragraphs) of query i<sup>th</sup> ,</p>
                                    <p>F2<sub>i</sub>= &nbsp;&nbsp;&nbsp;<span style="text-decoration: underline;">(5 x Precision<sub>i</sub> x Recall<sub>i</sub>)</span><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4 Precision<sub>i</sub> + Recall<sub>i</sub>)</p>
                                    <p>F2 = average of (F2<sub>i</sub>)</p>
                                    <p></p>
                                    <p></p>
                                    <p></p>
                                 </center>
                                 <p></p>
                                 <p></p>
                                 <p>In addition to the above evaluation measures, ordinal information retrieval measures such as Mean Average Precision and R-precision can be used for discussing the characteristics of the submission results.</p>
                                 <p>In ALQAC 2021, the method used to calculate the final evaluation score of all queries is macro-average (evaluation measure is calculated for each query and their average is used as the final evaluation measure) instead of micro-average (evaluation measure is calculated using results of all queries).</p>
                                 <h4 id="mce_27">Task 2: Legal Textual Entailment</h4>
                                 <p>Task 2’s goal is to construct Yes/No question answering systems for legal queries, by entailment from the relevant articles. Based on the content of legal articles, the system should answer whether the statement is true or false. </p>
                                 <p>Specifically, the input samples consist of the pair of question/statement and relevant articles (&gt;= 1) as follows:</p>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement"
            }
        ]</code></pre>
                                 <p>The system should answer whether the question/statement is true or false via <strong><em>“label”</em></strong> in JSON format as follows:</p>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement",
                "relevant_articles": [
                    {
                        "law_id": "45/2019/QH14",
                        "article_id": "1"
                    }
                ]
            }
        ]</code></pre>
                                 <p>The evaluation measure will be accuracy, with respect to whether the yes/no question was correctly confirmed: </p>
                                 <center> 					        Accuracy = <span style="text-decoration:underline;">(the number of queries which were correctly confirmed as true or false)</span><br> 							                                               (the number of all queries)<br> 																		           </center>
                                 <p>In addition to the above evaluation measures, ordinal information retrieval measures such as Mean Average Precision and R-precision can be used for discussing the characteristics of the submission results.</p>
                                 <h4 id="mce_43">Task 3: Legal Question Answering</h4>
                                 <p>Task 3’s goal is to construct Yes/No question answering systems for legal queries. </p>
                                 <p>Given a legal statement or legal question, the task is to answer “Yes” or “No”, in other words, to determine whether it is true or false. This question answering could be a concatenation of Task 1 and Task 2, but not necessarily so, e.g. using any knowledge source other than the results of Task 2.</p>
                                 <p>Specifically, the input samples consist of the question/statement as follows:</p>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement"
            }
        ]</code></pre>
                                 <p>The system should answer whether the question/statement is true or false via <strong><em>“label”</em></strong> in JSON format as follows:</p>
                                 <pre class="wp-block-code"><code>[
            {
                "question_id": "q-1",
                "text": "The content of question or statement",
                "relevant_articles": [
                    {
                        "law_id": "45/2019/QH14",
                        "article_id": "1"
                    }
                ]
            }
        ]</code></pre>
                                 <p>The evaluation measure will be accuracy, with respect to whether the yes/no question was correctly confirmed: </p>
                                 <center> 					        Accuracy = <span style="text-decoration:underline;">(the number of queries which were correctly confirmed as true or false)</span><br> 							                                               (the number of all queries)<br> 																		           </center>
                                 <p>In addition to the above evaluation measures, ordinal information retrieval measures such as Mean Average Precision and R-precision can be used for discussing the characteristics of the submission results.</p>
                                 <h3>Submission Details</h3>
                                 <p>Participants are required to submit a paper on their method and experimental results. The participants have to submit via <strong>e-mail</strong> files containing the results of each task, separately. For each task, participants can submit a <strong>maximum of 3 results corresponding to 3 different settings/methods</strong>. The code for evaluation is published on google colab (<a href="https://colab.research.google.com/drive/1aLK03wNldd4glo9Lh8SpyOH6AQAu0iKe#scrollTo=NpLncXEKpp60" data-type="URL" data-id="https://colab.research.google.com/drive/1aLK03wNldd4glo9Lh8SpyOH6AQAu0iKe#scrollTo=NpLncXEKpp60">https://colab.research.google.com/drive/1aLK03wNldd4glo9Lh8SpyOH6AQAu0iKe#scrollTo=NpLncXEKpp60</a>). </p>
                                 <p>In this framework, we defined a mentioned input/output data structure and evaluation methods for all 3 tasks.  </p>
                                 <blockquote class="wp-block-quote">
                                    <p></p>
                                    <p><strong>Note</strong>: Participants have a responsibility to warranty their result files have the same required structure.  </p>
                                 </blockquote>
                                 <p>These examples are outputs of 3 tasks that participants’ model needs to generate for evaluation methods:</p>
                                 <h4>Task 1: Legal documents’ Retrieval</h4>
                                 <pre class="wp-block-code"><code>
        [     
                {         
                    "question_id": "q-193",         
                    "relevant_articles": [             
                            {            
                                    "law_id": "100/2015/QH13",                 
                                    "article_id": "177"             
                            }         
                        ]     
                },     
                ... 
        ]</code></pre>
                                 <h4>Task 2: Entailment of Legal Question</h4>
                                 <pre class="wp-block-code"><code>
        [     
                {         
                    "question_id": "q-193",         
                    "label": false     
                },     
                ... 
        ]</code></pre>
                                 <h4>Task 3: Legal Question Answering</h4>
                                 <pre class="wp-block-code"><code>
        [     
                {         
                    "question_id": "q-193",         
                    "label": false     
                },     
                ... 
        ]</code></pre>
                                 <p></p>
                                 <p>At least one of the authors of an accepted paper has to present the paper at the ALQAC workshop of KSE 2021. </p>
                                 <p>The papers authored by the task winners will be included in the main KSE 2021 proceedings if ALQAC organizers admit the paper novelty after the review process.</p>
                                 <p>Papers should conform to the standards set out at the KSE 2021 webpage (section Submission) and be submitted to EasyChair. </p>
                                 <h2>Application Details</h2>
                                 <p>Potential participants to ALQAC-2021 should respond to this call for participation by submitting an application via: <strong><a href="https://tinyurl.com/ALQACRegistration"></a><a rel="noreferrer noopener" href="https://tinyurl.com/ALQACRegistration" target="_blank">tinyurl.com/ALQACRegistration</a></strong>. </p>
                                 <h2><strong>Schedule</strong></h2>
                                 <pre class="wp-block-preformatted"><strong>July 1, 2021</strong> Call for participation 
<strong>July 15, 2021</strong> Registration deadline 
<strong>July 15, 2021</strong> Training data release (via contact email in registration) 
<strong>August 20, 2021</strong> Testing data release (via contact email in registration) 
<strong>August 24, 2021 (11:59 p.m GMT+7): </strong>Submission deadline of Task 1 and Task 3
<strong>September 1, 2021 <strong>(11:59 p.m GMT+7)</strong></strong>:<strong> </strong>Submission deadline of Task 2 
<strong>September 5, 2021</strong> Announcements of rankings/assessments  
<strong>September 15, 2021</strong> Paper Submission in KSE Workshop: ALQAC <strong>
<strong>September 18, 2021</strong></strong> Notification of Acceptance 
<strong>September 25, 2021</strong> Camera-ready Submission 
<strong>November 10-12, 2021</strong> KSE 2021</pre>
                                 <h2>Task winners</h2>
                                 <p>Task 1: First prize: <strong>Aleph</strong>, Second prize: <strong>AimeLaw</strong>  </p>
                                 <p>Task 2: Two teams first prize: <strong>AimeLaw</strong> &amp; <strong>Aleph</strong>, Second prize: <strong>Kodiak</strong></p>
                                 <p>Task 3: First prize: <strong>Aleph</strong>, two teams second prize: <strong>AimeLaw</strong> &amp; <strong>Dat N</strong></p>
                                 <p>The detailed result of all submissions:</p>
                                 <figure class="wp-block-image size-large"><a href="./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32.png"><img loading="lazy" width="1024" height="356" src="./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32-1024x356.png" alt="" class="wp-image-392" srcset="./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32-1024x356.png 1024w, ./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32-300x104.png 300w, ./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32-768x267.png 768w, ./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32-1536x534.png 1536w, ./images/2021-09-Screen-Shot-2021-09-06-at-16.07.32.png 1558w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
                                 <p>  </p>
                                 <h2>Questions and Further Information</h2>
                                 <p>Email: <a href="lttung@jaist.ac.jp">lttung(at)jaist.ac.jp</a> with the subject <strong>[ALQAC-2021] &lt;Content&gt;</strong></p>
                                 <h2>Program Committee</h2>
                                 <p>Nguyen Le Minh, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Teeradaj Racharak, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Tran Duc Vu,&nbsp; The Institute of Statistical Mathematics (ISM), Japan</p>
                                 <p>Phan Viet Anh, Le Quy Don Technical University (LQDTU), Vietnam</p>
                                 <p>Nguyen Truong Son, Ho Chi Minh University of Science (VNU-HCMUS), Vietnam</p>
                                 <p>Nguyen Tien Huy, Ho Chi Minh University of Science (VNU-HCMUS), Vietnam</p>
                                 <p>Peerapon Vateekul, Chulalongkorn University (CU), Thailand</p>
                                 <p>Prachya Boonkwan, National Electronics and Computer Technology Center (NECTEC), Thailand</p>
                                 <p>Nguyen Ha Thanh, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Le Thanh Tung, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Bui Minh Quan, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Dang Tran Binh, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Vuong Thi Hai Yen, University of Engineering and Technology (VNU-UET), Vietnam</p>
                                 <p>Nguyen Minh Phuong, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                                 <p>Nguyen Minh Chau, Japan Advanced Institute of Science and Technology (JAIST), Japan</p>
                              </div>
                              <!-- .entry-content -->    	
                              <footer class="entry-footer">  			</footer>
                              <!-- .entry-footer -->  
                           </article>
                           <!-- #post-## -->    		
                        </main>
                        <!-- #main -->  	
                     </div>
                     <!-- #primary -->      <!-- #secondary -->              
                  </div>
               </div>
            </div>
            <!-- #content -->    	<!-- #colophon -->      
            <div class="footer-overlay"></div>
         </div>
         <!-- done for accessibility reasons -->  
      </div>
      <!-- #page -->    
      <link rel="stylesheet" id="academicons-css" href="./css/teachpress-includes-academicons-css-academicons.min.css" type="text/css" media="all">
      <link rel="stylesheet" id="font-awesome-css" href="./css/teachpress-includes-fontawesome-css-all.min.css" type="text/css" media="all">
      <script type="text/javascript" src="./js/embed-any-document-js-pdfobject.min.js" id="awsm-ead-pdf-object-js"></script> <script type="text/javascript" id="awsm-ead-public-js-extra">
         var education_zone_data = {"rtl":""};
         /* ]]> */
      </script> <script type="text/javascript" src="./js/education-zone-js-custom.min.js" id="education-zone-custom-js"></script> <script type="text/javascript" src="./js/5or-wp-embed.min.js" id="wp-embed-js"></script>     
   </body>
</html>
